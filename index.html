<!DOCTYPE html>
<html lang="en">


<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="styles.css" type="text/css">
    <title>Yatong Bai</title>
</head>


<body>
    <table summary="Table for page layout." class="tlayout">

        <!-- Navigation bar on the left -->
        <td id="layout-menu">
            <div style="margin-bottom:4px"></div>
            <div class="menu-item"><a href="index.html" class="current">Home</a></div>
            <div class="menu-item"><a href="publications.html">Publications</a></div>
            <div class="menu-item"><a href="teaching.html">Teaching</a></div>
            <div class="menu-item"><a href="coursework.html">Coursework</a></div>
            <div><hr></div>
            <div class="menu-item"><a 
                href="https://scholar.google.com/citations?hl=en&user=A9h086cAAAAJ"
                target=&ldquo;blank&rdquo;>Google Scholar</a></div>
            <div class="menu-item"><a 
                href="https://www.semanticscholar.org/author/Yatong-Bai/2115297196"
                target=&ldquo;blank&rdquo;>Semantic Scholar</a></div>
            <div class="menu-item"><a href="https://www.linkedin.com/in/yatong-bai" 
                target=&ldquo;blank&rdquo;>LinkedIn</a></div>
            <div class="menu-item"><a href="https://github.com/Bai-YT" 
                target=&ldquo;blank&rdquo;>GitHub</a></div>
            <div class="menu-item"><a href="files/index/Resume Yatong Bai Two Pages.pdf" 
                target=&ldquo;blank&rdquo;>CV</a></div>
        </td>

        <!-- Main contents -->
        <td id="layout-content">
            <div id="toptitle">
                <h1>Yatong Bai</h1>
            </div>

            <!-- Avatar photo and quick links -->
            <table class="imgtable">
                <td>
                    <img src="files/index/Photo.jpg" alt="Yatong Bai" width="260px" />&nbsp;
                </td>

                <td>
                    <section class="panel">
                        <p class="intro_large">Ph.D. Candidate</p>

                        <p class="intro_large">University of California, Berkeley</p>

                        <p class="intro_large">
                            Advisor: <a href="https://people.eecs.berkeley.edu/~sojoudi/" 
                            target=&ldquo;blank&rdquo;>Somayeh Sojoudi</a>
                        </p>

                        <p class="intro">
                            Email: <a href="mailto:yatong\_bai@berkeley.edu" 
                            target=&ldquo;blank&rdquo;>yatong_bai (at) berkeley.edu</a>
                        </p>

                        <div style="height:8px;"></div>

                        <p class="intro_tight">
                            <a href="https://scholar.google.com/citations?hl=en&user=A9h086cAAAAJ" 
                            target=&ldquo;blank&rdquo;>Google Scholar</a> &nbsp;&nbsp;&nbsp;
                            <a href="https://www.semanticscholar.org/author/Yatong-Bai/2115297196"
                            target=&ldquo;blank&rdquo;>Semantic Scholar</a></a>
                        </p>

                        <p class="intro_tight">
                            <a href="https://www.linkedin.com/in/yatong-bai" target=&ldquo;blank&rdquo;>LinkedIn</a>
                            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                            <a href="https://github.com/Bai-YT" target=&ldquo;blank&rdquo;>GitHub</a>
                            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                            <a href="files/index/Resume Yatong Bai Two Pages.pdf" target=&ldquo;blank&rdquo;>CV</a>
                        </p>
                    </section>
                </td>
            </table>

            <!-- Open to work -->
            <section class="panel_highlight">
                <i><b>I am open to full-time opportunities starting in 2025.</b></i>
            </section>

            <!-- About -->
            <section class="panel2">
                <h2>About</h2>

                <p>
                    I am a rising fifth-year Ph.D. candidate at the <a href="https://me.berkeley.edu"
                    target=&ldquo;blank&rdquo;>mechanical engineering</a> department of 
                    <a href="https://www.berkeley.edu" target=&ldquo;blank&rdquo;>UC Berkeley</a>, advised by Professor 
                    <a href="https://people.eecs.berkeley.edu/~sojoudi/" target=&ldquo;blank&rdquo;>Somayeh Sojoudi</a>.
                </p>

                <p>
                    Prior to joining Berkeley, I obtained two Bachelor's degrees in computer engineering
                    and mechanical engineering from 
                    <a href="https://www.gatech.edu" target=&ldquo;blank&rdquo;>Georgia Institute of Technology</a>, 
                    where I researched with Professors 
                    <a href="https://www.me.gatech.edu/faculty/meaud" target=&ldquo;blank&rdquo;>Julien Meaud</a> 
                    and <a href=https://www.ece.gatech.edu/faculty-staff-directory/tom-conte 
                    target=&ldquo;blank&rdquo;>Thomas Conte</a>.
                </p>

                <p>
                    I have interned at 
                    <a href="https://www.adobe.com" target=&ldquo;blank&rdquo;>Adobe</a>, 
                    <a href="https://www.microsoft.com" target=&ldquo;blank&rdquo;>Microsoft</a>, 
                    <a href="https://scale.com" target=&ldquo;blank&rdquo;>Scale AI</a>, 
                    <a href="https://www.hondajet.com" target=&ldquo;blank&rdquo;>Honda Aircraft Company</a>, and 
                    <a href="https://www.tesla.com" target=&ldquo;blank&rdquo;>Tesla</a>.
                </p>
            </section>

            <!-- Research insterests -->
            <section class="panel2">
                <h2>Research interests</h2>

                <p>
                    My interests include generative models (particulaly audio/music), robust deep learning, (convex) optimization, and controls.
                </p>
                <p>
                    Specifically, I enjoy working on ensuring the adversarial robustness of neural networks, addressing 
                    the "accuracy-robustness trade-off", and accelerating their training via theoretically disciplined 
                    methods, while still maintaining their impressive performances.
                </p>
                <p>
                    I also strive to accelerate audio generation models while preserving their generation quality and diversity.
                </p>
            </section>

            <!-- News -->
            <section class="section">
                <h2>News</h2>

                <ul>
                    <li><p>
                        <b>August 2024:</b> Our paper
                        <a href="https://arxiv.org/abs/2402.02263" target=&ldquo;blank&rdquo;>
                            “MixedNUTS: Training-Free Accuracy-Robustness Balance via Nonlinearly Mixed Classifiers”</a>
                        has been accepted to <a href="https://jmlr.org/tmlr"
                            target=&ldquo;blank&rdquo;>Transactions on Machine Learning Research (TMLR)</a>.
                    </p></li>

                    <li><p>
                        <b>July 2024:</b> I served as a reviewer for the 
                        <a href="https://neurips.cc/Conferences/2024" target=&ldquo;blank&rdquo;>NeurIPS 2024</a> conference.
                    </p></li>

                    <li><p>
                        <b>June 2024:</b> New paper 
                        <a href="https://arxiv.org/abs/2406.03589" target=&ldquo;blank&rdquo;>
                            “Ranking Manipulation for Conversational Search Engines”</a>
                            by Samuel Pfrommer, <b>Yatong bai</b>, Tanmay Gautam, and Somayeh Sojoudi.
                        Project code <a href="https://github.com/spfrommer/ranking_manipulation"
                            target=&ldquo;blank&rdquo;>on GitHub</a>.
                        This work proposes the "RAGDOLL" dataset, which is available on
                        <a href="https://huggingface.co/datasets/Bai-YT/RAGDOLL"
                            target=&ldquo;blank&rdquo;>Huggingface Datasets</a>.
                    </p></li>

                    <li><p>
                        <b>June 2024:</b> Our paper
                        <a href="https://arxiv.org/abs/2309.10740" target=&ldquo;blank&rdquo;>
                            “ConsistencyTTA: Accelerating Diffusion-Based Text-to-Audio Generation with Consistency Distillation”</a>
                        has been accepted to <a href="https://interspeech2024.org"
                            target=&ldquo;blank&rdquo;>the INTERSPEECH conference of 2024</a>.
                        <b>Live demo available at <a href="https://huggingface.co/spaces/Bai-YT/ConsistencyTTA" 
                            target=&ldquo;blank&rdquo;>Huggingface</a>. Feel free to try it out!</b>
                    </p></li>

                    <li><p>
                        <b>March 2024:</b> Our paper
                        <a href="https://arxiv.org/abs/2301.12554" target=&ldquo;blank&rdquo;>
                            Improving the Accuracy-Robustness Trade-Off of Classifiers via Adaptive Smoothing</a> has been accepted
                        to <a href="https://www.siam.org/publications/journals/siam-journal-on-mathematics-of-data-science-simods"
                            target=&ldquo;blank&rdquo;>the SIAM Journal on Mathematics of Data Science (SIMODS)</a>.
                    </p></li>

                    <li><p>
                        <b>March 2024:</b> I served as a reviewer for the 
                        <a href="https://icml.cc/Conferences/2024" target=&ldquo;blank&rdquo;>ICML 2024</a> conference.
                    </p></li>

                    <li><p>
                        <b>March 2024:</b> Our paper
                        <a href="https://arxiv.org/abs/2311.15165" target=&ldquo;blank&rdquo;>
                            Mixing Classifiers to Alleviate the Accuracy-Robustness Trade-Off</a>
                        has been accepted to <a href="https://l4dc.web.ox.ac.uk"
                            target=&ldquo;blank&rdquo;>the 6th Annual Learning for Dynamics & Control Conference</a>.
                    </p></li>

                    <li><p>
                        <b>February 2024:</b> We have open-sourced the training and evaluation code of the paper
                        “ConsistencyTTA: Accelerating Diffusion-Based Text-to-Audio Generation with Consistency Distillation”
                        at <a href="https://github.com/Bai-YT/ConsistencyTTA" 
                            target=&ldquo;blank&rdquo;>github.com/Bai-YT/ConsistencyTTA</a>.
                        The model checkpoints are shared on <a href="https://huggingface.co/Bai-YT/ConsistencyTTA" 
                            target=&ldquo;blank&rdquo;>Huggingface</a>.
                    </p></li>

                    <li><p>
                        <b>February 2024:</b> New paper
                        <a href="https://arxiv.org/abs/2402.02263" target=&ldquo;blank&rdquo;>
                            “MixedNUTS: Training-Free Accuracy-Robustness Balance via Nonlinearly Mixed Classifiers”</a>
                        by <b>Yatong Bai</b>, Mo Zhou, Vishal M. Patel, and Somayeh Sojoudi.
                        Project code <a href="https://github.com/Bai-YT/MixedNUTS" 
                            target=&ldquo;blank&rdquo;>github.com/Bai-YT/MixedNUTS</a>.
                    </p></li>

                    <li><p>
                        <b>February 2024:</b> I prepared summarization notes about Nonlinear Optimization for Professor Javad Lavaei's
                        <a href="https://lavaei.ieor.berkeley.edu/Course_IEOR160_Fall_2023.html" target=&ldquo;blank&rdquo;>IEOR 160</a>
                        course and made it publicly available <a href="teaching.html" target=&ldquo;blank&rdquo;>on this website</a>.
                    </p></li>

                    <li><p>
                        <b>December 2023:</b> I will join <a href="https://research.adobe.com/" 
                            target=&ldquo;blank&rdquo;>Adobe Research</a> 
                        as a Research Intern in May 2024. I will be working with 
                        <a href="https://research.adobe.com/person/nicholas-j-bryan/" 
                            target=&ldquo;blank&rdquo;>Nicholas J. Bryan</a>.
                    </p></li>

                    <li><p>
                        <b>October 2023:</b> I served as a reviewer for the 
                        <a href="https://iclr.cc/Conferences/2024" target=&ldquo;blank&rdquo;>ICLR 2024</a> conference.
                    </p></li>

                    <li><p>
                        <b>September 2023:</b> New paper 
                        <a href="https://arxiv.org/abs/2309.10740" target=&ldquo;blank&rdquo;>
                            “ConsistencyTTA: Accelerating Diffusion-Based Text-to-Audio Generation with Consistency Distillation”</a>
                        by <b>Yatong Bai</b>, Trung Dang, Dung Tran, Kazuhito Koishida, and Somayeh Sojoudi.
                        This work accelerates text-to-audio generation by up to 400x.
                        Project website <a href="https://consistency-tta.github.io" 
                            target=&ldquo;blank&rdquo;>consistency-tta.github.io</a>. Code is open-sourced.
                    </p></li>

                    <li><p>
                        <b>August 2023:</b> I served as a Graduate Student Instructor (GSI) for 
                        <a href="https://lavaei.ieor.berkeley.edu/Course_IEOR160_Fall_2023.html" 
                            target=&ldquo;blank&rdquo;>IEOR 160: Nonlinear and Discrete Optimization</a>
                        in the Fall 2023 semester.
                    </p></li>

                    <li><p>
                        <b>July 2023:</b> Our paper 
                        <a href="https://arxiv.org/abs/2307.15980" target=&ldquo;blank&rdquo;>
                            Initial State Interventions for Deconfounded Imitation Learning</a>
                        has been accepted to <a href="https://cdc2023.ieeecss.org" target=&ldquo;blank&rdquo;>
                            the IEEE Conference on Decision and Control (CDC)</a>.
                    </p></li>

                    <li><p>
                        <b>June 2023:</b> I served as a reviewer for the 
                        <a href="https://nips.cc/" target=&ldquo;blank&rdquo;>NeurIPS 2023</a> conference.
                    </p></li>

                    <li><p>
                        <b>April 2023:</b> I served as a reviewer for the <a href="https://cdc2023.ieeecss.org"
                        target=&ldquo;blank&rdquo;>2023 IEEE Conference on Decision and Control (CDC)</a>.
                    </p></li>

                    <li><p>
                        <b>February 2023:</b> I served as a reviewer for the 
                        <a href="https://icml.cc/Conferences/2023" target=&ldquo;blank&rdquo;>ICML 2023</a> and 
                        <a href="https://ieeeccta.org/" target=&ldquo;blank&rdquo;>IEEE CCTA 2023</a> conferences.
                    </p></li>

                    <li><p>
                        <b>January 2023:</b> New paper 
                        <a href="https://arxiv.org/abs/2301.12554" target=&ldquo;blank&rdquo;>
                            “Improving the Accuracy-Robustness Trade-Off of Classifiers via Local Adaptive Smoothing”</a>
                        by <b>Yatong Bai</b>, Brendon G. Anderson, Aerin Kim, and Somayeh Sojoudi.
                    </p></li>

                    <li><p>
                        <b>January 2023:</b> New paper 
                        <a href="https://arxiv.org/abs/2401.04575" target=&ldquo;blank&rdquo;>
                            “Let's Go Shopping (LGS) — Web-scale Image-text Dataset for Visual Concept Understanding”</a>
                        by <b>Yatong Bai</b>, Utsav Garg, Erhan Bas, Isidora Filipovic, Apaar Shanker, 
                        Haoming Zhang, Samyak Parajuli, Amelia N. Chu, Eugenia D Fomitcheva, 
                        Elliot Branson, Aerin Kim, Somayeh Sojoudi, and Kyunghyun Cho.
                    </p></li>

                    <li><p>
                        <b>December 2022:</b> I will join <a href="https://www.microsoft.com/applied-sciences" 
                            target=&ldquo;blank&rdquo;>Microsoft Applied Science</a> 
                        as a Research Intern in May 2023. I will be working with 
                        <a href="https://www.microsoft.com/applied-sciences/people/kazuhito-koishida" 
                            target=&ldquo;blank&rdquo;>Kazuhito Koishida</a>.
                    </p></li>

                    <li><p>
                        <b>December 2022:</b> I presented our poster on convex neural
                            network training at the year-end TBSI Symposium.
                    </p></li>

                    <li><p>
                        <b>October 2022:</b> Our paper 
                        <a href="https://arxiv.org/abs/2201.01965" target=&ldquo;blank&rdquo;>
                            “Efficient Global Optimization of Two-layer ReLU Networks: 
                            Adversarial Training and Quadratic-time Algorithms”</a> has been accepted to
                        <a href="https://www.siam.org/publications/journals/siam-journal-on-mathematics-of-data-science-simods"
                            target=&ldquo;blank&rdquo;> the SIAM Journal on Mathematics of Data Science (SIMODS)</a>.
                    </p></li>

                    <li><p>
                        <b>August 2022:</b> I am serving as a Graduate Student Instructor (GSI) for 
                        <a href="https://lavaei.ieor.berkeley.edu/Course_IEOR160_Fall_2022.html" 
                            target=&ldquo;blank&rdquo;>IEOR 160: Nonlinear and Discrete Optimization</a>
                        of the Fall 2022 semester.
                    </p></li>

                    <li><p>
                        <b>May 2022:</b> I have joined <a href="https://scale.com" target=&ldquo;blank&rdquo;>
                            Scale AI</a> as a Machine Learning Research Intern.
                            I will be working on a bi-modal dataset project with 
                            <a href="https://github.com/aerinkim" target=&ldquo;blank&rdquo;>Aerin Kim</a>.
                    </p></li>

                    <li><p>
                        <b>May 2022:</b> I have passed the Qualifying Examination and advanced to candidacy as a Ph.D. candidate.
                    </p></li>

                    <li><p>
                        <b>April 2022:</b> I served as a reviewer for the <a href="https://cdc2022.ieeecss.org"
                        target=&ldquo;blank&rdquo;>2022 IEEE Conference on Decision and Control (CDC)</a>.
                    </p></li>

                    <li><p>
                        <b>January 2022:</b> Our paper 
                        <a href="https://people.eecs.berkeley.edu/~sojoudi/ACC_YA_22.pdf" target=&ldquo;blank&rdquo;>
                            “Practical Convex Formulation of Robust Two-layer Neural Network Training”</a>
                            has been accepted to the American Control Conference of 2022.
                    </p></li>

                    <li><p>
                        <b>January 2022:</b> I am serving as a Graduate Student Instructor (GSI) for 
                        <a href="https://lavaei.ieor.berkeley.edu/Course_IEOR160_Spring_2022.html" target=&ldquo;blank&rdquo;>
                            IEOR 160: Nonlinear and Discrete Optimization</a>
                        of the Spring 2022 semester.
                    </p></li>

                    <li><p>
                        <b>December 2021:</b> New paper 
                        <a href="https://arxiv.org/abs/2201.01965" target=&ldquo;blank&rdquo;>
                            “Efficient Global Optimization of Two-layer ReLU Networks: 
                            Adversarial Training and Quadratic-time Algorithms”</a>
                            by <b>Yatong bai</b>, Tanmay Gautam, and Somayeh Sojoudi.
                    </p></li>

                    <li><p>
                        <b>October 2021:</b> I gave a talk on convex neural network adversarial training at INFORMS 2021.
                    </p></li>

                    <li><p>
                        <b>October 2021:</b> The paper “Efficient Global Optimization of Two-layer ReLU Networks: 
                        Adversarial Training and Quadratic-time Algorithms” received the 2021 <a href="https://www.informs.org/" 
                        target=&ldquo;blank&rdquo;>INFORMS</a> Data Mining Best Student Paper Award Runner-Up (2nd out of 48 papers).
                    </p></li>

                    <li><p>
                        <b>August 2021:</b> I gave a talk on convex neural network adversarial training at MOPTA 2021.
                    </p></li>

                    <li><p>
                        <b>August 2021:</b> I have passed the Preliminary Examination.
                    </p></li>

                    <li><p>
                        <b>April 2021:</b> I received the ECE Senior Scholar Award from the 
                        <a href=https://www.ece.gatech.edu/news/646699/ece-faculty-staff-and-students-receive-honors-roger-p-webb-awards-program
                        target=&ldquo;blank&rdquo;>Roger P. Webb Awards Program</a> at Georgia Tech.
                    </p></li>

                    <li><p>
                        <b>December 2020:</b> New paper on convex neural network adversarial training:
                        <a href="https://people.eecs.berkeley.edu/~sojoudi/ACC_YA_22.pdf" target=&ldquo;blank&rdquo;>
                            “Practical Convex Formulation of Robust Two-layer Neural Network Training”</a> 
                            by <b>Yatong Bai</b>, Tanmay Gautam, Yu Gai, and Somayeh Sojoudi.
                    </p></li>

                    <li><p>
                        <b>August 2020:</b> I have joined UC Berkeley as a Ph.D. student.
                    </p></li>

                    <li><p>
                        <b>August 2020:</b> I have graduated from Georgia Institute of Technology with B. S. degrees in 
                        Computer Engineering and Mechanical Engineering with a cumulative GPA of 4.00 out of 4.00.
                    </p></li>
                </ul>
            </section>
        </td>

    </table>
</body>

</html>
